{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('iris.data', sep=\",\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_idx(iris_name):\n",
    "    if iris_name == 'Iris-setosa':\n",
    "        return 0\n",
    "    elif iris_name == 'Iris-versicolor':\n",
    "        return 1\n",
    "    elif iris_name == 'Iris-virginica':\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = np.vectorize(name_idx)(data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([data[5:50], data[55:100], data[105:150]])\n",
    "test_df = pd.concat([data[0:5], data[50:55], data[100:105]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[[0,1,2,3]]\n",
    "Y_train = train_df['target']\n",
    "X_test = test_df[[0,1,2,3]]\n",
    "Y_test = test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencoder(df):\n",
    "    n_df = len(df)\n",
    "    onehotencoded = np.zeros((n_df, 3))\n",
    "    for i in range(n_df):\n",
    "        if df.values[i] == 0:\n",
    "            onehotencoded[i] = [1, 0, 0]\n",
    "        elif df.values[i] == 1:\n",
    "            onehotencoded[i] = [0, 1, 0]\n",
    "        elif df.values[i] == 2:\n",
    "            onehotencoded[i] = [0, 0, 1]\n",
    "    return onehotencoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_onehotencoded = onehotencoder(Y_train)\n",
    "Y_test_onehotencoded = onehotencoder(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_train_onehotencoded))\n",
    "print(len(Y_test_onehotencoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "X_train_rs = np.reshape(X_train.values, (X_train.values.shape[0], X_train.values.shape[1], 1))\n",
    "X_test_rs = np.reshape(X_test.values, (X_test.values.shape[0], X_test.values.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 4, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_rs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "n_input_layer = 4\n",
    "n_output_layer = 3\n",
    "n_hidden_layer = round(math.sqrt((n_input_layer*n_output_layer)))\n",
    "look_back = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(LSTM(n_hidden_layer, input_shape=(n_input_layer, 1)))\n",
    "# model.add(layers.Dense(n_hidden_layer, input_dim=n_input_layer, activation='tanh'))\n",
    "model.add(layers.Dense(n_output_layer, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x7f8717265210>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f87172bfe50>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 3)                 60        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 72\n",
      "Trainable params: 72\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135 samples\n",
      "Epoch 1/150\n",
      "135/135 [==============================] - 2s 16ms/sample - loss: 0.6379 - accuracy: 0.6667\n",
      "Epoch 2/150\n",
      "135/135 [==============================] - 0s 435us/sample - loss: 0.6368 - accuracy: 0.6667\n",
      "Epoch 3/150\n",
      "135/135 [==============================] - 0s 870us/sample - loss: 0.6362 - accuracy: 0.6667\n",
      "Epoch 4/150\n",
      "135/135 [==============================] - 0s 715us/sample - loss: 0.6356 - accuracy: 0.6667\n",
      "Epoch 5/150\n",
      "135/135 [==============================] - 0s 846us/sample - loss: 0.6351 - accuracy: 0.6667\n",
      "Epoch 6/150\n",
      "135/135 [==============================] - 0s 428us/sample - loss: 0.6346 - accuracy: 0.6667\n",
      "Epoch 7/150\n",
      "135/135 [==============================] - 0s 681us/sample - loss: 0.6341 - accuracy: 0.6667\n",
      "Epoch 8/150\n",
      "135/135 [==============================] - 0s 691us/sample - loss: 0.6336 - accuracy: 0.6667\n",
      "Epoch 9/150\n",
      "135/135 [==============================] - 0s 710us/sample - loss: 0.6330 - accuracy: 0.6667\n",
      "Epoch 10/150\n",
      "135/135 [==============================] - 0s 429us/sample - loss: 0.6324 - accuracy: 0.6667\n",
      "Epoch 11/150\n",
      "135/135 [==============================] - 0s 382us/sample - loss: 0.6316 - accuracy: 0.6667\n",
      "Epoch 12/150\n",
      "135/135 [==============================] - 0s 423us/sample - loss: 0.6308 - accuracy: 0.6667\n",
      "Epoch 13/150\n",
      "135/135 [==============================] - 0s 410us/sample - loss: 0.6302 - accuracy: 0.6667\n",
      "Epoch 14/150\n",
      "135/135 [==============================] - 0s 550us/sample - loss: 0.6288 - accuracy: 0.6667\n",
      "Epoch 15/150\n",
      "135/135 [==============================] - 0s 590us/sample - loss: 0.6275 - accuracy: 0.6667\n",
      "Epoch 16/150\n",
      "135/135 [==============================] - 0s 628us/sample - loss: 0.6259 - accuracy: 0.6667\n",
      "Epoch 17/150\n",
      "135/135 [==============================] - 0s 544us/sample - loss: 0.6240 - accuracy: 0.6667\n",
      "Epoch 18/150\n",
      "135/135 [==============================] - 0s 428us/sample - loss: 0.6221 - accuracy: 0.6667\n",
      "Epoch 19/150\n",
      "135/135 [==============================] - 0s 473us/sample - loss: 0.6195 - accuracy: 0.6667\n",
      "Epoch 20/150\n",
      "135/135 [==============================] - 0s 480us/sample - loss: 0.6171 - accuracy: 0.6667\n",
      "Epoch 21/150\n",
      "135/135 [==============================] - 0s 481us/sample - loss: 0.6147 - accuracy: 0.6667\n",
      "Epoch 22/150\n",
      "135/135 [==============================] - 0s 473us/sample - loss: 0.6121 - accuracy: 0.6667\n",
      "Epoch 23/150\n",
      "135/135 [==============================] - 0s 486us/sample - loss: 0.6093 - accuracy: 0.6667\n",
      "Epoch 24/150\n",
      "135/135 [==============================] - 0s 402us/sample - loss: 0.6068 - accuracy: 0.6667\n",
      "Epoch 25/150\n",
      "135/135 [==============================] - 0s 629us/sample - loss: 0.6036 - accuracy: 0.6667\n",
      "Epoch 26/150\n",
      "135/135 [==============================] - 0s 717us/sample - loss: 0.6008 - accuracy: 0.6667\n",
      "Epoch 27/150\n",
      "135/135 [==============================] - 0s 690us/sample - loss: 0.5974 - accuracy: 0.6667\n",
      "Epoch 28/150\n",
      "135/135 [==============================] - 0s 517us/sample - loss: 0.5941 - accuracy: 0.6667\n",
      "Epoch 29/150\n",
      "135/135 [==============================] - 0s 439us/sample - loss: 0.5905 - accuracy: 0.6667\n",
      "Epoch 30/150\n",
      "135/135 [==============================] - 0s 463us/sample - loss: 0.5872 - accuracy: 0.6667\n",
      "Epoch 31/150\n",
      "135/135 [==============================] - 0s 618us/sample - loss: 0.5833 - accuracy: 0.6667\n",
      "Epoch 32/150\n",
      "135/135 [==============================] - 0s 671us/sample - loss: 0.5797 - accuracy: 0.6667\n",
      "Epoch 33/150\n",
      "135/135 [==============================] - 0s 640us/sample - loss: 0.5757 - accuracy: 0.6667\n",
      "Epoch 34/150\n",
      "135/135 [==============================] - 0s 699us/sample - loss: 0.5717 - accuracy: 0.6667\n",
      "Epoch 35/150\n",
      "135/135 [==============================] - 0s 471us/sample - loss: 0.5677 - accuracy: 0.6667\n",
      "Epoch 36/150\n",
      "135/135 [==============================] - 0s 465us/sample - loss: 0.5636 - accuracy: 0.6667\n",
      "Epoch 37/150\n",
      "135/135 [==============================] - 0s 501us/sample - loss: 0.5592 - accuracy: 0.6667\n",
      "Epoch 38/150\n",
      "135/135 [==============================] - 0s 506us/sample - loss: 0.5546 - accuracy: 0.6667\n",
      "Epoch 39/150\n",
      "135/135 [==============================] - 0s 511us/sample - loss: 0.5500 - accuracy: 0.6667\n",
      "Epoch 40/150\n",
      "135/135 [==============================] - 0s 442us/sample - loss: 0.5453 - accuracy: 0.6716\n",
      "Epoch 41/150\n",
      "135/135 [==============================] - 0s 512us/sample - loss: 0.5417 - accuracy: 0.6716\n",
      "Epoch 42/150\n",
      "135/135 [==============================] - 0s 434us/sample - loss: 0.5355 - accuracy: 0.6741\n",
      "Epoch 43/150\n",
      "135/135 [==============================] - 0s 496us/sample - loss: 0.5305 - accuracy: 0.6815\n",
      "Epoch 44/150\n",
      "135/135 [==============================] - 0s 464us/sample - loss: 0.5250 - accuracy: 0.6914\n",
      "Epoch 45/150\n",
      "135/135 [==============================] - 0s 412us/sample - loss: 0.5194 - accuracy: 0.6988\n",
      "Epoch 46/150\n",
      "135/135 [==============================] - 0s 470us/sample - loss: 0.5136 - accuracy: 0.7012\n",
      "Epoch 47/150\n",
      "135/135 [==============================] - 0s 459us/sample - loss: 0.5082 - accuracy: 0.7012\n",
      "Epoch 48/150\n",
      "135/135 [==============================] - 0s 393us/sample - loss: 0.5011 - accuracy: 0.7210\n",
      "Epoch 49/150\n",
      "135/135 [==============================] - 0s 446us/sample - loss: 0.4953 - accuracy: 0.7235\n",
      "Epoch 50/150\n",
      "135/135 [==============================] - 0s 386us/sample - loss: 0.4885 - accuracy: 0.7383\n",
      "Epoch 51/150\n",
      "135/135 [==============================] - 0s 473us/sample - loss: 0.4816 - accuracy: 0.7506\n",
      "Epoch 52/150\n",
      "135/135 [==============================] - 0s 400us/sample - loss: 0.4748 - accuracy: 0.7728\n",
      "Epoch 53/150\n",
      "135/135 [==============================] - 0s 573us/sample - loss: 0.4682 - accuracy: 0.7827\n",
      "Epoch 54/150\n",
      "135/135 [==============================] - 0s 852us/sample - loss: 0.4614 - accuracy: 0.8025\n",
      "Epoch 55/150\n",
      "135/135 [==============================] - 0s 907us/sample - loss: 0.4530 - accuracy: 0.8198\n",
      "Epoch 56/150\n",
      "135/135 [==============================] - 0s 505us/sample - loss: 0.4457 - accuracy: 0.8420\n",
      "Epoch 57/150\n",
      "135/135 [==============================] - 0s 454us/sample - loss: 0.4380 - accuracy: 0.8444\n",
      "Epoch 58/150\n",
      "135/135 [==============================] - 0s 470us/sample - loss: 0.4302 - accuracy: 0.8519\n",
      "Epoch 59/150\n",
      "135/135 [==============================] - 0s 481us/sample - loss: 0.4231 - accuracy: 0.8469\n",
      "Epoch 60/150\n",
      "135/135 [==============================] - 0s 540us/sample - loss: 0.4155 - accuracy: 0.8543\n",
      "Epoch 61/150\n",
      "135/135 [==============================] - 0s 580us/sample - loss: 0.4083 - accuracy: 0.8543\n",
      "Epoch 62/150\n",
      "135/135 [==============================] - 0s 468us/sample - loss: 0.4017 - accuracy: 0.8494\n",
      "Epoch 63/150\n",
      "135/135 [==============================] - 0s 541us/sample - loss: 0.3937 - accuracy: 0.8543\n",
      "Epoch 64/150\n",
      "135/135 [==============================] - 0s 605us/sample - loss: 0.3871 - accuracy: 0.8568\n",
      "Epoch 65/150\n",
      "135/135 [==============================] - 0s 624us/sample - loss: 0.3803 - accuracy: 0.8568\n",
      "Epoch 66/150\n",
      "135/135 [==============================] - 0s 714us/sample - loss: 0.3741 - accuracy: 0.8617\n",
      "Epoch 67/150\n",
      "135/135 [==============================] - 0s 436us/sample - loss: 0.3681 - accuracy: 0.8593\n",
      "Epoch 68/150\n",
      "135/135 [==============================] - 0s 578us/sample - loss: 0.3633 - accuracy: 0.8568\n",
      "Epoch 69/150\n",
      "135/135 [==============================] - 0s 779us/sample - loss: 0.3577 - accuracy: 0.8617\n",
      "Epoch 70/150\n",
      "135/135 [==============================] - 0s 720us/sample - loss: 0.3545 - accuracy: 0.8716\n",
      "Epoch 71/150\n",
      "135/135 [==============================] - 0s 757us/sample - loss: 0.3483 - accuracy: 0.8691\n",
      "Epoch 72/150\n",
      "135/135 [==============================] - 0s 449us/sample - loss: 0.3434 - accuracy: 0.8815\n",
      "Epoch 73/150\n",
      "135/135 [==============================] - 0s 483us/sample - loss: 0.3398 - accuracy: 0.8938\n",
      "Epoch 74/150\n",
      "135/135 [==============================] - 0s 490us/sample - loss: 0.3357 - accuracy: 0.8988\n",
      "Epoch 75/150\n",
      "135/135 [==============================] - 0s 529us/sample - loss: 0.3316 - accuracy: 0.9012\n",
      "Epoch 76/150\n",
      "135/135 [==============================] - 0s 465us/sample - loss: 0.3277 - accuracy: 0.8988\n",
      "Epoch 77/150\n",
      "135/135 [==============================] - 0s 509us/sample - loss: 0.3246 - accuracy: 0.9086\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 492us/sample - loss: 0.3220 - accuracy: 0.9086\n",
      "Epoch 79/150\n",
      "135/135 [==============================] - 0s 546us/sample - loss: 0.3181 - accuracy: 0.9086\n",
      "Epoch 80/150\n",
      "135/135 [==============================] - 0s 477us/sample - loss: 0.3159 - accuracy: 0.9086\n",
      "Epoch 81/150\n",
      "135/135 [==============================] - 0s 465us/sample - loss: 0.3127 - accuracy: 0.9160\n",
      "Epoch 82/150\n",
      "135/135 [==============================] - 0s 397us/sample - loss: 0.3095 - accuracy: 0.9210\n",
      "Epoch 83/150\n",
      "135/135 [==============================] - 0s 479us/sample - loss: 0.3072 - accuracy: 0.9259\n",
      "Epoch 84/150\n",
      "135/135 [==============================] - 0s 423us/sample - loss: 0.3043 - accuracy: 0.9235\n",
      "Epoch 85/150\n",
      "135/135 [==============================] - 0s 360us/sample - loss: 0.3017 - accuracy: 0.9210\n",
      "Epoch 86/150\n",
      "135/135 [==============================] - 0s 415us/sample - loss: 0.2990 - accuracy: 0.9284\n",
      "Epoch 87/150\n",
      "135/135 [==============================] - 0s 371us/sample - loss: 0.2970 - accuracy: 0.9284\n",
      "Epoch 88/150\n",
      "135/135 [==============================] - 0s 364us/sample - loss: 0.2949 - accuracy: 0.9284\n",
      "Epoch 89/150\n",
      "135/135 [==============================] - 0s 417us/sample - loss: 0.2930 - accuracy: 0.9333\n",
      "Epoch 90/150\n",
      "135/135 [==============================] - 0s 512us/sample - loss: 0.2902 - accuracy: 0.9284\n",
      "Epoch 91/150\n",
      "135/135 [==============================] - 0s 414us/sample - loss: 0.2879 - accuracy: 0.9358\n",
      "Epoch 92/150\n",
      "135/135 [==============================] - 0s 423us/sample - loss: 0.2861 - accuracy: 0.9309\n",
      "Epoch 93/150\n",
      "135/135 [==============================] - 0s 366us/sample - loss: 0.2836 - accuracy: 0.9284\n",
      "Epoch 94/150\n",
      "135/135 [==============================] - 0s 362us/sample - loss: 0.2820 - accuracy: 0.9383\n",
      "Epoch 95/150\n",
      "135/135 [==============================] - 0s 425us/sample - loss: 0.2802 - accuracy: 0.9358\n",
      "Epoch 96/150\n",
      "135/135 [==============================] - 0s 398us/sample - loss: 0.2776 - accuracy: 0.9358\n",
      "Epoch 97/150\n",
      "135/135 [==============================] - 0s 435us/sample - loss: 0.2765 - accuracy: 0.9358\n",
      "Epoch 98/150\n",
      "135/135 [==============================] - 0s 424us/sample - loss: 0.2742 - accuracy: 0.9432\n",
      "Epoch 99/150\n",
      "135/135 [==============================] - 0s 468us/sample - loss: 0.2735 - accuracy: 0.9358\n",
      "Epoch 100/150\n",
      "135/135 [==============================] - 0s 463us/sample - loss: 0.2711 - accuracy: 0.9383\n",
      "Epoch 101/150\n",
      "135/135 [==============================] - 0s 388us/sample - loss: 0.2688 - accuracy: 0.9407\n",
      "Epoch 102/150\n",
      "135/135 [==============================] - 0s 454us/sample - loss: 0.2669 - accuracy: 0.9481\n",
      "Epoch 103/150\n",
      "135/135 [==============================] - 0s 361us/sample - loss: 0.2657 - accuracy: 0.9457\n",
      "Epoch 104/150\n",
      "135/135 [==============================] - 0s 363us/sample - loss: 0.2637 - accuracy: 0.9457\n",
      "Epoch 105/150\n",
      "135/135 [==============================] - 0s 377us/sample - loss: 0.2618 - accuracy: 0.9432\n",
      "Epoch 106/150\n",
      "135/135 [==============================] - 0s 528us/sample - loss: 0.2605 - accuracy: 0.9457\n",
      "Epoch 107/150\n",
      "135/135 [==============================] - 0s 714us/sample - loss: 0.2587 - accuracy: 0.9506\n",
      "Epoch 108/150\n",
      "135/135 [==============================] - 0s 717us/sample - loss: 0.2576 - accuracy: 0.9506\n",
      "Epoch 109/150\n",
      "135/135 [==============================] - 0s 744us/sample - loss: 0.2562 - accuracy: 0.9457\n",
      "Epoch 110/150\n",
      "135/135 [==============================] - 0s 847us/sample - loss: 0.2544 - accuracy: 0.9506\n",
      "Epoch 111/150\n",
      "135/135 [==============================] - 0s 620us/sample - loss: 0.2525 - accuracy: 0.9531\n",
      "Epoch 112/150\n",
      "135/135 [==============================] - 0s 654us/sample - loss: 0.2511 - accuracy: 0.9531\n",
      "Epoch 113/150\n",
      "135/135 [==============================] - 0s 598us/sample - loss: 0.2518 - accuracy: 0.9506\n",
      "Epoch 114/150\n",
      "135/135 [==============================] - 0s 684us/sample - loss: 0.2488 - accuracy: 0.9531\n",
      "Epoch 115/150\n",
      "135/135 [==============================] - 0s 902us/sample - loss: 0.2470 - accuracy: 0.9531\n",
      "Epoch 116/150\n",
      "135/135 [==============================] - 0s 763us/sample - loss: 0.2462 - accuracy: 0.9531\n",
      "Epoch 117/150\n",
      "135/135 [==============================] - 0s 686us/sample - loss: 0.2445 - accuracy: 0.9506\n",
      "Epoch 118/150\n",
      "135/135 [==============================] - 0s 628us/sample - loss: 0.2429 - accuracy: 0.9531\n",
      "Epoch 119/150\n",
      "135/135 [==============================] - 0s 733us/sample - loss: 0.2417 - accuracy: 0.9556\n",
      "Epoch 120/150\n",
      "135/135 [==============================] - 0s 921us/sample - loss: 0.2419 - accuracy: 0.9531\n",
      "Epoch 121/150\n",
      "135/135 [==============================] - 0s 400us/sample - loss: 0.2393 - accuracy: 0.9481\n",
      "Epoch 122/150\n",
      "135/135 [==============================] - 0s 557us/sample - loss: 0.2377 - accuracy: 0.9605\n",
      "Epoch 123/150\n",
      "135/135 [==============================] - 0s 411us/sample - loss: 0.2367 - accuracy: 0.9580\n",
      "Epoch 124/150\n",
      "135/135 [==============================] - 0s 480us/sample - loss: 0.2362 - accuracy: 0.9531\n",
      "Epoch 125/150\n",
      "135/135 [==============================] - 0s 481us/sample - loss: 0.2345 - accuracy: 0.9531\n",
      "Epoch 126/150\n",
      "135/135 [==============================] - 0s 599us/sample - loss: 0.2330 - accuracy: 0.9605\n",
      "Epoch 127/150\n",
      "135/135 [==============================] - 0s 599us/sample - loss: 0.2315 - accuracy: 0.9580\n",
      "Epoch 128/150\n",
      "135/135 [==============================] - 0s 822us/sample - loss: 0.2303 - accuracy: 0.9556\n",
      "Epoch 129/150\n",
      "135/135 [==============================] - 0s 426us/sample - loss: 0.2292 - accuracy: 0.9506\n",
      "Epoch 130/150\n",
      "135/135 [==============================] - 0s 498us/sample - loss: 0.2286 - accuracy: 0.9605\n",
      "Epoch 131/150\n",
      "135/135 [==============================] - 0s 461us/sample - loss: 0.2286 - accuracy: 0.9481\n",
      "Epoch 132/150\n",
      "135/135 [==============================] - 0s 488us/sample - loss: 0.2257 - accuracy: 0.9580\n",
      "Epoch 133/150\n",
      "135/135 [==============================] - 0s 592us/sample - loss: 0.2246 - accuracy: 0.9605\n",
      "Epoch 134/150\n",
      "135/135 [==============================] - 0s 531us/sample - loss: 0.2238 - accuracy: 0.9605\n",
      "Epoch 135/150\n",
      "135/135 [==============================] - 0s 530us/sample - loss: 0.2229 - accuracy: 0.9556\n",
      "Epoch 136/150\n",
      "135/135 [==============================] - 0s 637us/sample - loss: 0.2217 - accuracy: 0.9556\n",
      "Epoch 137/150\n",
      "135/135 [==============================] - 0s 813us/sample - loss: 0.2215 - accuracy: 0.9457\n",
      "Epoch 138/150\n",
      "135/135 [==============================] - 0s 874us/sample - loss: 0.2204 - accuracy: 0.9580\n",
      "Epoch 139/150\n",
      "135/135 [==============================] - 0s 721us/sample - loss: 0.2182 - accuracy: 0.9580\n",
      "Epoch 140/150\n",
      "135/135 [==============================] - 0s 580us/sample - loss: 0.2166 - accuracy: 0.9580\n",
      "Epoch 141/150\n",
      "135/135 [==============================] - 0s 392us/sample - loss: 0.2163 - accuracy: 0.9531\n",
      "Epoch 142/150\n",
      "135/135 [==============================] - 0s 481us/sample - loss: 0.2151 - accuracy: 0.9580\n",
      "Epoch 143/150\n",
      "135/135 [==============================] - 0s 517us/sample - loss: 0.2148 - accuracy: 0.9506\n",
      "Epoch 144/150\n",
      "135/135 [==============================] - 0s 530us/sample - loss: 0.2130 - accuracy: 0.9556\n",
      "Epoch 145/150\n",
      "135/135 [==============================] - 0s 632us/sample - loss: 0.2130 - accuracy: 0.9605\n",
      "Epoch 146/150\n",
      "135/135 [==============================] - 0s 557us/sample - loss: 0.2113 - accuracy: 0.9605\n",
      "Epoch 147/150\n",
      "135/135 [==============================] - 0s 530us/sample - loss: 0.2108 - accuracy: 0.9556\n",
      "Epoch 148/150\n",
      "135/135 [==============================] - 0s 569us/sample - loss: 0.2091 - accuracy: 0.9556\n",
      "Epoch 149/150\n",
      "135/135 [==============================] - 0s 659us/sample - loss: 0.2098 - accuracy: 0.9531\n",
      "Epoch 150/150\n",
      "135/135 [==============================] - 0s 649us/sample - loss: 0.2071 - accuracy: 0.9580\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f871407e250>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_rs, Y_train_onehotencoded, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1, 3.5, 1.4, 0.2] => 0 (expected 0)\n",
      "[4.9, 3.0, 1.4, 0.2] => 0 (expected 0)\n",
      "[4.7, 3.2, 1.3, 0.2] => 0 (expected 0)\n",
      "[4.6, 3.1, 1.5, 0.2] => 0 (expected 0)\n",
      "[5.0, 3.6, 1.4, 0.2] => 0 (expected 0)\n",
      "[7.0, 3.2, 4.7, 1.4] => 2 (expected 1)\n",
      "[6.4, 3.2, 4.5, 1.5] => 1 (expected 1)\n",
      "[6.9, 3.1, 4.9, 1.5] => 2 (expected 1)\n",
      "[5.5, 2.3, 4.0, 1.3] => 1 (expected 1)\n",
      "[6.5, 2.8, 4.6, 1.5] => 1 (expected 1)\n",
      "[6.3, 3.3, 6.0, 2.5] => 2 (expected 2)\n",
      "[5.8, 2.7, 5.1, 1.9] => 2 (expected 2)\n",
      "[7.1, 3.0, 5.9, 2.1] => 2 (expected 2)\n",
      "[6.3, 2.9, 5.6, 1.8] => 2 (expected 2)\n",
      "[6.5, 3.0, 5.8, 2.2] => 2 (expected 2)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(X_test_rs)\n",
    "# summarize the first 5 cases\n",
    "for i in range(len(X_test)):\n",
    "    print('%s => %d (expected %d)' % (X_test.values[i].tolist(), predictions[i], Y_test.values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 3.2, 4.7, 1.4] => 2 (expected 1)\n",
      "[6.9, 3.1, 4.9, 1.5] => 2 (expected 1)\n",
      "Errou: 2\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(15):\n",
    "    if predictions[i] != Y_test.values[i]:\n",
    "        print('%s => %d (expected %d)' % (X_test.values[i].tolist(), predictions[i], Y_test.values[i]))\n",
    "        cnt+=1\n",
    "print(\"Errou: %d\" % cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
